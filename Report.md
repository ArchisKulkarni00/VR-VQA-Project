# Script Reports

## ExtractListings.py  
### Purpose  
Extracts all `.gz` compressed files from a specified directory, decompresses them, and saves the extracted data as uncompressed files. Designed for data curation tasks involving dataset decompression.  

---

### Key Functions  
**`extract_gz_files(folder_path)`**  
- **Functionality**: Iterates through files in the directory, extracts `.gz` files, and saves them as uncompressed files.  
- **Workflow**:  
  1. Lists all files in the directory.  
  2. Filters files ending with `.gz`.  
  3. Decompresses each file using `gzip.open` and writes output to a new file.  
  4. Prints confirmation for each extracted file.  

---

### Dependencies  
- **Standard Library**: `os`, `gzip`, `shutil` (no external libraries required).  

---

## GenerateCSV.py  
### Purpose  
Processes JSON files from a directory, extracts structured data (`main_image_id` and `product_type` fields), and writes results to a CSV file. Designed for JSON-to-CSV conversion with filtering.  

---

### Key Functions  
**`main()`**  
- **Functionality**: Orchestrates file scanning, JSON parsing, data extraction, and CSV writing.  
- **Workflow**:  
  1. Defines input directory and output CSV path.  
  2. Scans directory for `.json` files.  
  3. Parses JSON objects, filters rows with required keys, and extracts `main_image_id` and `product_type` (from nested lists).  
  4. Writes data to a CSV file with headers.  

---

### Configuration Variables  
- **`json_folder`**: Source directory for JSON files.  
- **`output_csv`**: Destination CSV file.  

---

### Dependencies  
- **Standard Library**: `os`, `json`, `csv`.  
- **Python Version**: Python 3.x (compatibility with `json` and `csv` modules).  

---

## MergeCSVFiles.py  
### Purpose  
Merges two CSV files (image metadata and product data), performs data cleaning, and produces a final CSV with valid image-product associations.  

---

### Key Functions/Classes  
- `pd.read_csv()`: Loads CSV files.  
- `pd.merge()`: Joins datasets on `image_id` and `main_image_id`.  
- `os.path.exists()`: Validates image file existence.  
- `drop_duplicates()`: Removes duplicate image records.  
- `to_csv()`: Saves final merged dataset.  

---

### Overall Architecture  
1. **Input Processing**:  
   - Reads `images.csv` (image metadata) and `filtered_products.csv` (product data).  
2. **Data Transformation**:  
   - Merges datasets on `image_id` and `main_image_id`.  
   - Filters to retain columns: `image_id`, `path`, `product_type`.  
   - Removes duplicate image records.  
1. **Validation**:  
   - Constructs full image paths using a base directory.  
   - Filters to retain only existing image files.  
4. **Output**:  
   - Saves cleaned data to `merged_output.csv`.  

---

### Dependencies  
- **Pandas**: For data manipulation (loading, merging, filtering).  
- **Os**: For file system operations.  

---

## DataAnalysis.py  
### Purpose  
Performs exploratory data analysis (EDA) on the merged CSV file generated by `MergeCSVFiles.py`, providing insights into dataset structure, quality, and product type distribution.  

---

### Key Functions/Classes  
- `pd.read_csv()`: Loads `merged_output.csv`.  
- `df.isnull().sum()`: Checks for missing values.  
- `df['product_type'].value_counts()`: Counts unique product types.  
- `df.describe()`: Generates summary statistics.  
- `df.sample()`: Extracts random samples.  
- `df.duplicated()`: Detects duplicate records.  

---

### Overall Architecture  
1. **Input Processing**:  
   - Loads `merged_output.csv` (output from `MergeCSVFiles.py`).  
2. **Data Exploration**:  
   - Checks for missing values.  
   - Analyzes `product_type` distribution.  
   - Shows sample image paths.  
   - Detects duplicate records.  
1. **Statistical Analysis**:  
   - Calculates summary statistics for all columns.  
   - Shows class distribution as percentages.  

---

### Dependencies  
- **Pandas**: For data manipulation and analysis.  
- **No external APIs or databases** required.

## OllamaMoonDream.py

### Purpose
This script generates visual question answering (VQA) responses for a subset of images in a CSV file using the Moondream model from Ollama. It processes image metadata to create detailed textual descriptions of products in image files.

### Key Functions/Classes
- `pd.read_csv()`: Load CSV data
- `ollama.Client()`: Connect to Ollama API
- `tqdm()`: Progress tracking for image processing
- `get_image_description()`: Core function for generating VQA responses
- `os.path.isfile()`: Validate image existence
- `CSV file tracking`: Incremental processing of outputs

### Overall Architecture
1. **Initialization**:
   - Configures parameters (CSV path, image column, model name, etc.)
   - Loads CSV data and selects a subset
   - Checks for existing output CSV to avoid reprocessing
2. **Model Integration**:
   - Connects to Ollama API (http://localhost:11434)
   - Uses Moondream model for image description generation
3. **Image Processing**:
   - For each image:
     - Validates file existence
     - Constructs prompt with product type
     - Sends image and prompt to model
     - Saves generated description
4. **Output Management**:
   - Appends results to CSV file
   - Tracks processed indices to avoid duplicates

### Dependencies
- **Pandas**: For CSV data handling
- **Ollama Python Client**: For interacting with the Moondream model
- **Tqdm**: For progress visualization
- **OS**: For file system operations

### Integration Points
- **Ollama API**: Uses Moondream model for image description generation
- **CSV Files**: 
  - Input: `sampled_balanced_output.csv` (contains image paths and product types)
  - Output: `vqa_output.csv` (contains image metadata + generated descriptions)
- **File System**: Requires access to image files in `BASE_IMAGE_DIR`

### Data Flow
1. Loads `sampled_balanced_output.csv` (from previous steps)
2. Processes a subset of images (START_INDEX to END_INDEX)
3. For each image:
   - Validates file existence
   - Sends image and product type to Moondream model
   - Stores generated description
4. Saves results to `vqa_output.csv` with index tracking


## OllamaL3.py

### Purpose
This script generates question-answer (QA) pairs from image descriptions generated by the `OllamaMoonDream.py` script, using the Llama3.2 model from Ollama. It processes a subset of image data to create structured QA pairs for visual question answering tasks.

### Key Functions/Classes
- `pd.read_csv()`: Load CSV data
- `ollama.Client()`: Connect to Ollama API
- `tqdm()`: Progress tracking for QA generation
- `generate_qa_from_description()`: Core function for QA generation
- `clean_and_parse_qa()`: Format and validate QA output
- `is_valid_qa()`: Check for valid QA pairs
- `os.path.exists()`: Check for existing output file

### Overall Architecture
1. **Initialization**:
   - Configures parameters (CSV path, model name, etc.)
   - Loads CSV data and selects a subset
   - Checks for existing output CSV to avoid reprocessing
2. **Model Integration**:
   - Connects to Ollama API (http://localhost:11434)
   - Uses Llama3.2 model for QA generation
3. **QA Generation**:
   - For each image description:
     - Sends prompt to model
     - Extracts QA pairs
     - Cleans and validates output
     - Saves to CSV
4. **Output Management**:
   - Appends results to CSV file
   - Tracks processed indices to avoid duplicates

### Dependencies
- **Pandas**: For CSV data handling
- **Ollama Python Client**: For interacting with the Llama3.2 model
- **Tqdm**: For progress visualization
- **Re**: For regex-based text cleaning
- **OS**: For file system operations

### Integration Points
- **Ollama API**: Uses Llama3.2 model for QA generation
- **CSV Files**:
  - Input: `vqa_output.csv` (contains image descriptions)
  - Output: `vqa_qa_cleaned.csv` (contains image metadata + QA pairs)
- **File System**: Requires access to image files (via `vqa_output.csv`)

### Data Flow
1. Loads `vqa_output.csv` (from previous steps)
2. Processes a subset of images (START_INDEX to END_INDEX)
3. For each image:
   - Retrieves description from CSV
   - Sends prompt to Llama3.2 model
   - Extracts QA pairs
   - Cleans and validates output
   - Stores in `vqa_qa_cleaned.csv`
4. Saves results with index tracking to avoid duplicates
